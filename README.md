# Fine-Tuning Lightweight Stable Diffusion for Image-to-Image Generation

This repository demonstrates how to fine-tune a lightweight Stable Diffusion model for image-to-image generation. The project consists of two notebooks:

1. **Image Generation Notebook**: Generates new images based on the CIFAR-10 dataset using a pre-trained Stable Diffusion model.
2. **Fine-Tuning Notebook**: Fine-tunes the model to enhance its image generation capabilities.

## Requirements

- Python 3.7+
- Google Colab (for easy execution in the cloud)
- GPU (recommended for faster execution)
- Necessary libraries:
  - `torch`
  - `torchvision`
  - `diffusers`
  - `PIL`
  - `google.colab`

## Setup

1. **Mount Google Drive**: The images generated by the model are saved to Google Drive, so you will need to mount it for easy access.
   
2. **Device Setup**: The model will automatically use GPU or CPU depending on availability, ensuring faster processing when using a GPU.

## Workflow

### 1. Image Generation Notebook

- **Model**: A lightweight Stable Diffusion model (`stabilityai/stable-diffusion-2-1-base`) is used to generate new images.
- **Dataset**: The CIFAR-10 dataset is used as the input, with images resized to a resolution of 512x512.
- **Generation Process**: The model generates new images based on the original CIFAR-10 images, using a fixed prompt and adjustable parameters such as strength and guidance scale.
- **Output**: The generated images are saved to a directory in your Google Drive, and the labels from the CIFAR-10 dataset are displayed for reference.

### 2. Fine-Tuning Notebook

In this notebook, the pre-trained model is further trained (fine-tuned) on custom data to improve the image generation quality. Key steps include:
- Preparing and loading the custom dataset.
- Freezing some layers of the model to retain pre-trained weights while focusing on learning new features.
- Fine-tuning the model on the new data with lower learning rates.

## License

This project is licensed under the MIT License.
