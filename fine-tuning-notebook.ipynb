{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom diffusers import StableDiffusionPipeline\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nimport numpy as np","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class StableDiffusionFinetuner:\n    def __init__(self, \n                 model_name=\"stabilityai/stable-diffusion-2-1-base\", \n                 epochs=10,  # Setting the number of epochs to 10\n                 batch_size=4,\n                 output_dir=\"/kaggle/working/fine_tuned_images\"):\n        \"\"\"\n        Initializing the fine-tuning process with configurable parameters.\n        \n        Args:\n            model_name (str): The name of the Stable Diffusion model to use\n            epochs (int): Number of training epochs\n            batch_size (int): The batch size for training\n            output_dir (str): Directory path to save generated images\n        \"\"\"\n        # Setting the device for running the model, using GPU if available\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"Using device: {self.device}\")\n\n        # Initializing model parameters based on user input\n        self.model_name = model_name\n        self.epochs = epochs\n        self.batch_size = batch_size\n        self.output_dir = output_dir\n\n        # Creating the directory to save generated images if it doesn't exist\n        os.makedirs(self.output_dir, exist_ok=True)\n\n        # Loading the Stable Diffusion model into the device\n        self.pipe = self.load_model()\n\n        # Preparing the data loader for training data\n        self.dataloader = self.prepare_data()\n\n        # Setting up an optimizer (AdamW) for model fine-tuning\n        self.optimizer = AdamW(self.pipe.unet.parameters(), lr=1e-5)\n\n    def load_model(self):\n        \"\"\"Loading the Stable Diffusion model from the Hugging Face model hub.\"\"\"\n        try:\n            # Loading the pre-trained model and moving it to the appropriate device (GPU or CPU)\n            pipe = StableDiffusionPipeline.from_pretrained(self.model_name).to(self.device)\n            return pipe\n        except Exception as e:\n            # Handling any errors during model loading\n            print(f\"Error loading model: {e}\")\n            raise\n\n    def prepare_data(self):\n        \"\"\"Preparing the CIFAR-10 dataset with necessary transformations.\"\"\"\n        # Defining image transformation to resize, convert to tensor, and normalize\n        transform = transforms.Compose([\n            transforms.Resize((512, 512)),  # Resizing images to 512x512\n            transforms.ToTensor(),  # Converting images to tensor format\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizing for pre-trained models\n        ])\n        \n        # Downloading and loading the CIFAR-10 dataset with the specified transformations\n        cifar10 = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n        \n        # Creating a DataLoader for batching, shuffling, and parallel data loading\n        dataloader = DataLoader(\n            cifar10, \n            batch_size=self.batch_size,  # Using the specified batch size\n            shuffle=True,  # Shuffling the dataset for better training\n            num_workers=2,  # Using 2 workers to load data in parallel\n            pin_memory=True  # Pinning memory for faster data transfer to GPU\n        )\n        \n        return dataloader\n\n    def generate_images(self, epoch, batch_idx, img, label):\n        \"\"\"\n        Generating images using two methods (text-to-image, image-to-image) with error handling.\n        \n        Args:\n            epoch (int): The current training epoch\n            batch_idx (int): The current batch index within the epoch\n            img (torch.Tensor): The input image tensor from the dataloader\n            label (torch.Tensor): The label of the image (for class name)\n        \"\"\"\n        try:\n            # Converting the image tensor to a PIL Image for generation\n            img_pil = transforms.ToPILImage()(img.cpu())\n            \n            # Retrieving the class name for the label to use in the generation prompts\n            class_name = self.dataloader.dataset.classes[label.item()]\n            \n            # Method 1: Generating an image from text prompt\n            try:\n                text_prompt = f\"A high-quality, detailed image of a {class_name}\"\n                # Generating an image from the text prompt\n                text_generated = self.pipe(\n                    prompt=text_prompt, \n                    num_inference_steps=50,  # Number of inference steps for generation\n                    guidance_scale=7.5  # Using higher guidance scale for better quality\n                ).images[0]\n                \n                # Defining the path to save the generated image\n                text_save_path = os.path.join(\n                    self.output_dir, \n                    f\"text_gen_epoch_{epoch+1}_batch_{batch_idx+1}.png\"\n                )\n                text_generated.save(text_save_path)  # Saving the generated image\n                print(f\"Saved text-to-image: {text_save_path}\")\n            except Exception as text_gen_error:\n                print(f\"Text-to-image generation error: {text_gen_error}\")\n            \n            # Method 2: Image-to-image generation using the input image as the base\n            try:\n                img2img_prompt = f\"Enhanced, photorealistic version of a {class_name}\"\n                # Generating a new image based on the input image and text prompt\n                img2img_generated = self.pipe(\n                    prompt=img2img_prompt, \n                    init_image=img_pil,  # Initial image for the transformation\n                    strength=0.75,  # Controlling how much of the initial image is preserved\n                    num_inference_steps=50,  # Number of inference steps for generation\n                    guidance_scale=7.5  # Using higher guidance scale for better quality\n                ).images[0]\n                \n                # Defining the path to save the generated image\n                img2img_save_path = os.path.join(\n                    self.output_dir, \n                    f\"img2img_gen_epoch_{epoch+1}_batch_{batch_idx+1}.png\"\n                )\n                img2img_generated.save(img2img_save_path)  # Saving the generated image\n                print(f\"Saved image-to-image: {img2img_save_path}\")\n            except Exception as img2img_gen_error:\n                print(f\"Image-to-image generation error: {img2img_gen_error}\")\n\n        except Exception as overall_error:\n            print(f\"Overall image generation error: {overall_error}\")\n\n    def fine_tune(self):\n        \"\"\"Main fine-tuning method with comprehensive error handling.\"\"\"\n        print(\"Starting fine-tuning process...\")\n        \n        # Iterating over the number of epochs\n        for epoch in range(self.epochs):\n            print(f\"Epoch {epoch+1}/{self.epochs}\")\n            \n            # Creating a progress bar for monitoring the training process\n            progress_bar = tqdm(\n                self.dataloader, \n                desc=f\"Epoch {epoch+1}\", \n                unit=\"batch\"\n            )\n            \n            # Iterating through batches in the dataloader\n            for batch_idx, (img, label) in enumerate(progress_bar):\n                try:\n                    # Moving image and label tensors to the device (GPU or CPU)\n                    img = img.to(self.device)\n                    label = label.to(self.device)\n                    \n                    # Generating images for this batch using the generate_images method\n                    self.generate_images(epoch, batch_idx, img[0], label[0])\n                    \n                    # Updating the progress bar with current batch details\n                    progress_bar.set_postfix({\n                        \"Batch\": batch_idx+1,  # Current batch number\n                        \"Label\": self.dataloader.dataset.classes[label[0].item()]  # Current batch label (class)\n                    })\n                    \n                except Exception as batch_error:\n                    # Handling errors during batch processing\n                    print(f\"Error in batch {batch_idx}: {batch_error}\")\n                    continue\n            \n            # Indicating successful completion of the current epoch\n            print(f\"Epoch {epoch+1} completed successfully!\")\n        \n        print(\"Fine-tuning process completed.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    # Initializing the fine-tuning process with specified parameters\n    fine_tuner = StableDiffusionFinetuner(\n        model_name=\"stabilityai/stable-diffusion-2-1-base\",  # Using Stable Diffusion model\n        epochs=10,  # Setting number of epochs to 10\n        batch_size=4  # Using batch size of 4\n    )\n    # Running the fine-tuning process\n    fine_tuner.fine_tune()\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}