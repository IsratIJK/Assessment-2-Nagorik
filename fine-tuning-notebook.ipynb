{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Installing the diffusers library, which is a popular library for diffusion models (generative models).\n# Using pip, the package installer for Python, to download and install the 'diffusers' package from PyPI (Python Package Index).\n# The 'diffusers' library includes various tools and models related to generative art, particularly focusing on Stable Diffusion and other diffusion-based models.\n\npip install diffusers\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from diffusers import StableDiffusionPipeline","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Importing the torch library, which provides functions for tensor computation and deep learning operations.\nimport torch\n\n# Importing the os library for interacting with the operating system, especially for file and directory operations.\nimport os\n\n# Importing DataLoader from torch.utils.data, which is used to load datasets in batches for efficient training.\nfrom torch.utils.data import DataLoader\n\n# Importing datasets and transforms from torchvision, which provides standard datasets and image transformation utilities.\nfrom torchvision import datasets, transforms\n\n# Importing the StableDiffusionPipeline class from diffusers, which allows to load and work with a pre-trained Stable Diffusion model.\nfrom diffusers import StableDiffusionPipeline  # Correct import\n\n# Importing tqdm, a progress bar utility for Python loops to visualize the processing status.\nfrom tqdm import tqdm\n\n# Importing AdamW, an optimizer class from torch.optim, which implements the Adam optimizer with weight decay.\nfrom torch.optim import AdamW\n\n# Importing nn from torch, which provides a set of neural network layers and utilities for model building.\nimport torch.nn as nn\n\n# Importing the Image class from the Python Imaging Library (PIL), used for opening, manipulating, and saving image files.\nfrom PIL import Image\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class StableDiffusionFinetuner:\n    def __init__(self, \n                 model_name=\"stabilityai/stable-diffusion-2-1-base\", \n                 epochs=10,  # Number of training epochs\n                 batch_size=4,  # Batch size for training\n                 output_dir=\"/kaggle/working/fine_tuned_images\",  # Output directory to save images\n                 lr=1e-5):  # Learning rate for fine-tuning\n        \"\"\"\n        Initializes fine-tuning with specified parameters.\n        \"\"\"\n        # Checking if a GPU is available. If not, it defaults to CPU.\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"Using device: {self.device}\")\n\n        # Setting the fine-tuning parameters like model name, epochs, batch size, output directory, and learning rate.\n        self.model_name = model_name\n        self.epochs = epochs\n        self.batch_size = batch_size\n        self.output_dir = output_dir\n        self.lr = lr\n\n        # Ensuring the output directory exists or creating it if it does not.\n        os.makedirs(self.output_dir, exist_ok=True)\n\n        # Loading the pre-trained model using the load_model method.\n        self.pipe = self.load_model()\n\n        # Preparing the data loader with the prepare_data method to handle training data.\n        self.dataloader = self.prepare_data()\n\n        # Creating the optimizer using AdamW, which is a commonly used optimizer for fine-tuning.\n        self.optimizer = AdamW(self.pipe.unet.parameters(), lr=self.lr)\n        \n        # Setting the loss function (MSE Loss) which is commonly used in generative models for fine-tuning.\n        self.criterion = nn.MSELoss()\n\n    def load_model(self):\n        \"\"\"Load the pre-trained Stable Diffusion model.\"\"\"\n        try:\n            # Loading the pre-trained Stable Diffusion model using the `from_pretrained` method from the diffusers library.\n            pipe = StableDiffusionPipeline.from_pretrained(self.model_name).to(self.device)\n            return pipe\n        except Exception as e:\n            # Handling any errors that may occur during model loading and raising an exception if needed.\n            print(f\"Error loading model: {e}\")\n            raise\n\n    def prepare_data(self):\n        \"\"\"Prepare the CIFAR-10 dataset for fine-tuning.\"\"\"\n        # Defining the data transformation pipeline to resize images, convert them to tensors, and normalize them.\n        transform = transforms.Compose([\n            transforms.Resize((512, 512)),  # Resizing images to 512x512 as required by the Stable Diffusion model\n            transforms.ToTensor(),  # Converting images to tensors for model input\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizing based on ImageNet stats\n        ])\n        \n        # Loading the CIFAR-10 dataset with the specified transformations.\n        cifar10 = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n        \n        # Creating a DataLoader for batching and shuffling the dataset.\n        dataloader = DataLoader(cifar10, batch_size=self.batch_size, shuffle=True)\n        \n        return dataloader\n\n    def generate_images(self, epoch, batch_idx, img, label):\n        \"\"\"\n        Generate images using image-to-image transformation.\n        \"\"\"\n        try:\n            # Converting the image tensor into a PIL image format for use with the model.\n            img_pil = transforms.ToPILImage()(img.cpu())\n    \n            # Generating the prompt based on the class label for image-to-image transformation.\n            class_name = self.dataloader.dataset.classes[label.item()]\n            img2img_prompt = f\"Enhanced, photorealistic version of a {class_name}\"\n    \n            # Generating an image by passing the prompt and input image to the Stable Diffusion model.\n            output = self.pipe(\n                prompt=img2img_prompt, \n                init_image=img_pil,  # Input image for transformation\n                strength=0.75,  # The strength controls how much the original image is modified\n                num_inference_steps=50,  # Number of steps to refine the image\n                guidance_scale=7.5  # Controls how strongly the model follows the prompt\n            )\n            \n            # Ensuring that the output contains at least one generated image.\n            img2img_generated = output.images[0]  # Taking the first generated image\n    \n            # Saving the generated image to the specified output directory.\n            img2img_save_path = os.path.join(self.output_dir, f\"img2img_gen_epoch_{epoch+1}_batch_{batch_idx+1}.png\")\n            img2img_generated.save(img2img_save_path)\n            print(f\"Saved generated image: {img2img_save_path}\")\n    \n            return img2img_generated\n    \n        except Exception as e:\n            # Handling any errors that may occur during the image generation process.\n            print(f\"Error during image generation: {e}\")\n            return None\n\n    def fine_tune(self):\n        \"\"\"Fine-tune the model over multiple epochs.\"\"\"\n        print(\"Starting fine-tuning...\")\n\n        # Looping over the number of epochs to fine-tune the model.\n        for epoch in range(self.epochs):\n            print(f\"Epoch {epoch + 1}/{self.epochs}\")\n\n            # Using a progress bar (from tqdm) to track the progress of each epoch.\n            progress_bar = tqdm(self.dataloader, desc=f\"Epoch {epoch + 1}\", unit=\"batch\")\n\n            # Looping through the data in batches for each epoch.\n            for batch_idx, (img, label) in enumerate(progress_bar):\n                try:\n                    # Moving the data to the GPU (if available).\n                    img = img.to(self.device)\n                    label = label.to(self.device)\n\n                    # Generating images for the current batch using the image-to-image method.\n                    generated_img = self.generate_images(epoch, batch_idx, img[0], label[0])\n\n                    if generated_img is not None:\n                        # Calculating the loss between the generated image and the original image.\n                        loss = self.criterion(generated_img, img[0])\n\n                        # Performing backpropagation by zeroing gradients, computing gradients, and updating the weights.\n                        self.optimizer.zero_grad()  # Clearing the previous gradients\n                        loss.backward()  # Computing gradients for the loss\n                        self.optimizer.step()  # Updating the model weights\n\n                        # Updating the progress bar with the current batch loss.\n                        progress_bar.set_postfix({\"Batch\": batch_idx + 1, \"Loss\": loss.item()})\n\n                except Exception as e:\n                    # Handling errors that may occur during the processing of each batch.\n                    print(f\"Error in batch {batch_idx}: {e}\")\n\n            # Printing the loss after each epoch to track fine-tuning progress.\n            print(f\"Epoch {epoch + 1} completed with loss: {loss.item()}\")\n\n        # Notifying the user that fine-tuning is completed.\n        print(\"Fine-tuning completed.\")\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}